{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#%pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                id     title  \\\n",
      "0     mzn81mgq52zn    Libros   \n",
      "1     e65gk2m48gjo    Libros   \n",
      "2     qzmyx19w7gzv    Libros   \n",
      "3     0j232kwk3r6y    Libros   \n",
      "4     qjwp59xom4zo    Libros   \n",
      "...            ...       ...   \n",
      "1075  wzvne24vrdjl  Teclados   \n",
      "1076  wzy5prkk1pj5  Teclados   \n",
      "1077  0j232n84qm6y  Teclados   \n",
      "1078  0j2328xonr6y  Teclados   \n",
      "1079  pzprorngk963  Teclados   \n",
      "\n",
      "                                                                                                imagen  \n",
      "0     https://cdn.wallapop.com/images/10420/et/ch/__/c10420p895818149/i3254482064.jpg?pictureSize=W640  \n",
      "1     https://cdn.wallapop.com/images/10420/et/ca/__/c10420p895808572/i3254430770.jpg?pictureSize=W640  \n",
      "2     https://cdn.wallapop.com/images/10420/et/ch/__/c10420p895817256/i3254478465.jpg?pictureSize=W640  \n",
      "3     https://cdn.wallapop.com/images/10420/et/cg/__/c10420p895816035/i3254473454.jpg?pictureSize=W640  \n",
      "4     https://cdn.wallapop.com/images/10420/et/bn/__/c10420p895779629/i3254277504.jpg?pictureSize=W640  \n",
      "...                                                                                                ...  \n",
      "1075  https://cdn.wallapop.com/images/10420/es/e2/__/c10420p894212389/i3248818847.jpg?pictureSize=W640  \n",
      "1076  https://cdn.wallapop.com/images/10420/es/b7/__/c10420p894078568/i3245740250.jpg?pictureSize=W640  \n",
      "1077  https://cdn.wallapop.com/images/10420/es/ea/__/c10420p894222383/i3246509455.jpg?pictureSize=W640  \n",
      "1078  https://cdn.wallapop.com/images/10420/es/at/__/c10420p894061035/i3245655570.jpg?pictureSize=W640  \n",
      "1079  https://cdn.wallapop.com/images/10420/er/xf/__/c10420p893436050/i3242173184.jpg?pictureSize=W640  \n",
      "\n",
      "[1080 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "with open('libros.json') as file:\n",
    "    libros = json.load(file)\n",
    "with open('teclados.json') as file:\n",
    "    teclados = json.load(file)   \n",
    "with open('mochilas.json') as file:\n",
    "    mochilas = json.load(file)    \n",
    " \n",
    "for item in libros:\n",
    "        item['title'] = 'Libro'   \n",
    "for item in teclados:\n",
    "        item['title'] = 'Teclado'\n",
    "for item in mochilas:\n",
    "        item['title'] = 'Mochila'    \n",
    "        \n",
    "cleaned_libros = []\n",
    "for item in libros:\n",
    "    medium_images = [image[\"medium\"] for image in item[\"images\"]]\n",
    "    cleaned_item = {\n",
    "        \"id\": item[\"id\"],\n",
    "        \"title\": \"Libros\",\n",
    "        \"imagen\": medium_images\n",
    "    }\n",
    "    cleaned_libros.append(cleaned_item)\n",
    "cleaned_teclados = []\n",
    "for item in teclados:\n",
    "    medium_images = [image[\"medium\"] for image in item[\"images\"]]\n",
    "    cleaned_item = {\n",
    "        \"id\": item[\"id\"],\n",
    "        \"title\": \"Teclados\",\n",
    "        \"imagen\": medium_images\n",
    "    }\n",
    "    cleaned_teclados.append(cleaned_item)\n",
    "cleaned_mochilas = []\n",
    "for item in mochilas:\n",
    "    medium_images = [image[\"medium\"] for image in item[\"images\"]]\n",
    "    cleaned_item = {\n",
    "        \"id\": item[\"id\"],\n",
    "        \"title\": \"Mochilas\",\n",
    "        \"imagen\": medium_images\n",
    "    }\n",
    "    cleaned_mochilas.append(cleaned_item)\n",
    "            \n",
    "                          \n",
    "df_libros=pd.DataFrame(cleaned_libros)\n",
    "df_teclados=pd.DataFrame(cleaned_teclados)\n",
    "df_mochilas=pd.DataFrame(cleaned_mochilas)\n",
    "\n",
    "#df_libros['title']=df_libros['title'].apply(lambda x: [object for object in x if object in relevant_objects])\n",
    "\n",
    "df = pd.DataFrame(cleaned_libros + cleaned_mochilas + cleaned_teclados)\n",
    "#df= df[['']]\n",
    "relevant_objects = ['Libro', 'Teclado', 'Mochila']\n",
    "#df['title'] = df['title'].apply(lambda x: [object for object in x if object in relevant_objects])\n",
    "\n",
    "\n",
    "df['imagen'] = df['imagen'].str[0].astype(str)\n",
    "\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "with pd.option_context('display.max_colwidth', 100):\n",
    "    print (df)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Split train data into train and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_val = X_val.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Create the model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('classifier_imagenes.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
